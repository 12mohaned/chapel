// HDFS iteration (AKA "map") module

/* ====================== TODO's/FIXME's ========================
 * 
 * Need to make sure that it is seeking properly in the file when we have blocks
   of one file spread across many hosts.
 
 * Need to optimize this ALOT more....
 
 * Need to look at host selection, apparently what I thought was happening actually
   wasnt... so we need to look at this as well

 * Need to look at what we would want in a reduce

 * add in asserts (i.e make program "safe")

 * Used Replicated vars in order to communicate the pointers across locales

 */

use Sys, HDFS, HDFStools, UtilReplicatedVar;

// ============== Serial iterator ========================
iter HDFSmap(dataFile: string, namenode: string = "default", port: int(32) = 0,
    domainSuffix: string = "", blockOverlap: int = 1024, closeFile: bool = true) {


  var hdfsFS: c_ptr = HDFS.hdfsConnect(namenode, port);
  var fileInfo = HDFS.chadoopGetFileInfo(hdfsFS, dataFile);
  var blockHosts = HDFS.hdfsGetHosts(hdfsFS, dataFile, 0, fileInfo.mSize); // incr 0?
  var blockCount = HDFS.chadoopGetBlockCount(blockHosts);
  // QUESTION: Might be worth it to put this on the locale
  var dataFileLocal = HDFS.hdfsOpenFile(hdfsFS, dataFile, O_RDONLY, 0, 0, 0);
  assert(HDFS.IS_NULL(dataFileLocal) == HDFS.IS_NULL_FALSE, "Failed to open dataFileLocal");
  var length = (fileInfo.mBlockSize + blockOverlap): int(32);

  var Blocks: [LocaleSpace] domain(int);
  // Setup a mapping loc --> block

  for i in 0..#blockCount {

    // need to do the magic-foo that was referenced above
    //  var owner = HDFS.chadoopGetHost(blockHosts, i: int(32), (i % fileInfo.mReplication): int(32));
    // FIXME: I feel this is FAR to fragile and domain specific to the problem at
    //        hand to be used widely. The easiest/most obvious option that I could think
    //        of was to add the domainSuffix. I feel as though we should keep it in
    //        case people want to use it, but that we should fix the problem with
    //        owner/locale names better and more elegantly. (Also it means we have to do
    //        string manipulation which is not all that great..)
    var owner_tmp = HDFS.chadoopGetHost(blockHosts, i: int(32), (i % fileInfo.mReplication): int(32)) + domainSuffix;
    var IDX = indexOf(".", owner_tmp, 1);
    var owner = owner_tmp.substring(1..IDX-1);

    for loc in Locales {
      if (loc.name == owner)
        then Blocks[loc.id] += i;
    }
  }

  writeln("Blocks are: ", Blocks);

  writeln("computing on ", here.name);

  for loc in Locales {
    for block in Blocks[loc.id] {
      var startByte = block * fileInfo.mBlockSize;
      if ((length + startByte) >= fileInfo.mSize) {
        length = (fileInfo.mSize - startByte): int(32);
      }
      var s = HDFS.chadoopReadFilePositional(hdfsFS, dataFileLocal, startByte, length);
      yield s; // owner is the locale that "owns" that block
    }
  }

  if (closeFile) {
    hdfsCloseFile(hdfsFS, dataFileLocal);
    writeln("closing file");
  }
}

// ======= Leader-follower iterator that should implement the above in parallel ====
iter HDFSmap(param tag: iterKind, dataFile: string, namenode: string = "default",
    port: int(32) = 0, domainSuffix: string = "", blockOverlap: int = 1024,
    closeFile: bool = true)
where tag == iterKind.leader {

  // ================== Globals and replication domains ==================
  var Blocks: [LocaleSpace] domain(int); // Our "work-queue"

  // Setup replication across our locales
  var hdfsFS_PL: [rcDomain] c_ptr;
  var fileInfo_PL: [rcDomain] chadoopFileInfo;
  var dataFileLocal_PL: [rcDomain] c_ptr; 
  var blockHosts_PL: [rcDomain] c_ptr;
  var blockCount_PL: [rcDomain] c_int;
  var length_PL: [rcDomain] int(32);
  // ====================== END ==========================================

  forall loc in Locales {
    on loc {

      writeln(here.name);

      //======================== File connection =========================
      var hdfsFS: c_ptr = HDFS.hdfsConnect(namenode, port);
      assert(HDFS.IS_NULL(hdfsFS) == HDFS.IS_NULL_FALSE, "Failed to connect to HDFS");

      var fileInfo = HDFS.chadoopGetFileInfo(hdfsFS, dataFile);
      var dataFileLocal = HDFS.hdfsOpenFile(hdfsFS, dataFile, O_RDONLY, 0, 0, 0);
      assert(HDFS.IS_NULL(dataFileLocal) == HDFS.IS_NULL_FALSE, "Failed to open dataFileLocal on loc ", here.id);
      // =================================== END =========================

      // ========== Native (Chapel) constants used throughout ============
      // These should all be covered under the PGAS model -- right?? 
      var length = (fileInfo.mBlockSize + blockOverlap): int(32);
      // =================================== END =========================

      // ========================== File-blocks ==========================
      // Get block info
      var blockHosts = HDFS.hdfsGetHosts(hdfsFS, dataFile, 0, fileInfo.mSize);
      var blockCount = HDFS.chadoopGetBlockCount(blockHosts);
      // =================================== END =========================

      // ================ Replication to Locales =========================
      // Copy over our stuff to all of our locales
      rcLocal(hdfsFS_PL)        = hdfsFS;
      rcLocal(fileInfo_PL)      = fileInfo;
      rcLocal(dataFileLocal_PL) = dataFileLocal;
      rcLocal(length_PL)        = length;

      // =================================== END =========================

      writeln("finished all the connecting");

      // =============== Setup ownership of blocks on locales ================ 
      // ===============    create per-locale work-queue      ================
      //
      // Setup a mapping loc --> {block1, block2, ...}
      forall i in 0..#blockCount { // for some reason were only getting evens here...

        //  var owner = HDFS.chadoopGetHost(blockHosts, i: int(32), (i % fileInfo.mReplication): int(32));
        // FIXME: I feel this is FAR to fragile and domain specific to the problem at
        //        hand to be used widely. The easiest/most obvious option that I could think
        //        of was to add the domainSuffix. I feel as though we should keep it in
        //        case people want to use it, but that we should fix the problem with
        //        owner/locale names better and more elegantly. (Also it means we have to do
        //        string manipulation which is not all that great..)

        var owner_tmp = HDFS.chadoopGetHost(blockHosts, i: int(32), (i % fileInfo.mReplication): int(32)) + domainSuffix;
        var IDX = indexOf(".", owner_tmp, 1);
        var owner = owner_tmp.substring(1..IDX-1);
        writeln("Owner: ", owner, " block: ", i, " locale " + here.name);

        // Setup ownership and work-queues using an associative domain
        if (loc.name == owner)// && !notIn(i, Blocks)) // If we own it, and somone else doesnt already have it
          then Blocks[loc.id] += i;
      }
    }
  }
  // =================================== END =============================

  writeln("Blocks are: ", Blocks);

  // ======= Pop off all our work on each locale work-queue on that locale ======
  //
  coforall loc in Locales { 
    on loc {

      // Get replicated values
      var fileInfo_LOCAL = rcLocal(fileInfo_PL);
      var hdfsFS_LOCAL = rcLocal(hdfsFS_PL);
      var dataFileLocal_LOCAL = rcLocal(dataFileLocal_PL);
      var length_LOCAL = rcLocal(length_PL);

      // Run through our "work queue"
      for block in Blocks[loc.id] { // might make this a forall
        var startByte = block * fileInfo_LOCAL.mBlockSize;
        if ((length_LOCAL + startByte) >= fileInfo_LOCAL.mSize) {
          length_LOCAL = (fileInfo_LOCAL.mSize - startByte): int(32);
        }
        var s = HDFS.chadoopReadFilePositional(hdfsFS_LOCAL, dataFileLocal_LOCAL, startByte, length_LOCAL);
        yield s; // owner is the locale that "owns" that block
      }
    }
  }
  // ============= Close oure file on each locale ==============
  if (closeFile) {
    for loc in Locales { 
      on loc { 
        var hdfsFS_LOCAL = rcLocal(hdfsFS_PL);
        var dataFileLocal_LOCAL = rcLocal(dataFileLocal_PL);
        hdfsCloseFile(hdfsFS_LOCAL, dataFileLocal_LOCAL);
        writeln("closing file on locale ", loc.id);
      }
    }
  }
}

// ======== Follower iterator =========================
iter HDFSmap(param tag: iterKind, dataFile: string, namenode: string = "default",
    port: int(32) = 0, domainSuffix: string = "", blockOverlap: int = 1024,
    closeFile: bool = true, followThis)
where tag == iterKind.follower {
  yield followThis;
}

proc notIn(i: int, Blocks) {
  for loc in Locales {
    if (Blocks[loc.id].member(i)) {
      return true;
      break;
    }
  }
}













